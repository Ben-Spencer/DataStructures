<h1>Course Notes</h1>
<h1>Preface</h1>
Courses are available at the following links:
<ul>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016/">Introduction to Computer Science and Programming in Python</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/">Introduction to Computational Thinking and Data Science</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/">Introduction to Algorithms</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/">Design and Analysis of Algorithms</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-851-advanced-data-structures-spring-2012/">Advanced Data Structures</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/">Artificial Intelligence</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-858-computer-systems-security-fall-2014/">Computer Systems Security</a></li>
 <li><a href="https://www.coursera.org/specializations/software-design-architecture">Software Design and Architecture Specialization</a></li>
 <ul>
  <li><a href="https://www.coursera.org/learn/object-oriented-design">Object-Oriented Design</a></li>
  <li><a href="https://www.coursera.org/learn/design-patterns">Design Patterns</a></li>
  <li><a href="https://www.coursera.org/learn/software-architecture">Software Architecture</a></li>
  <li><a href="https://www.coursera.org/learn/service-oriented-architecture">Service Oriented Architecture</a></li>
 </ul>
 <li><a href="https://www.coursera.org/specializations/advanced-machine-learning-tensorflow-gcp">Advanced Machine Learning with TensorFlow on Google Cloud Platform Specialization</a></li>
 <ul>
  <li><a href="https://www.coursera.org/learn/end-to-end-ml-tensorflow-gcp?specialization=advanced-machine-learning-tensorflow-gcp">End-to-End Machine Learning with TensorFlow on GCP</a></li>
  <li><a href="https://www.coursera.org/learn/gcp-production-ml-systems?specialization=advanced-machine-learning-tensorflow-gcp">Production Machine Learning Systems</a></li>
  <li><a href="https://www.coursera.org/learn/image-understanding-tensorflow-gcp?specialization=advanced-machine-learning-tensorflow-gcp">Image Understanding with TensorFlow on GCP</a></li>
  <li><a href="https://www.coursera.org/learn/sequence-models-tensorflow-gcp?specialization=advanced-machine-learning-tensorflow-gcp">Sequence Models for Time Series and Natural Language Processing</a></li>
  <li><a href="https://www.coursera.org/learn/recommendation-models-gcp">Recommendation Systems with TensorFlow on GCP</a></li>
 </ul>
</ul>
<br>
<h1>Table of Contents</h1>
<ul>
 <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#introduction-to-computer-science-and-programming-in-python">Introduction to Computer Science and Programming in Python</a></li>
 <ul>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-1-what-is-computation">Lecture 1: What is Computation?</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-2-branching-and-iteration">Lecture 2: Branching and Iteration</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-3-string-manipulation-guess-and-check-approximations-bisection">Lecture 3: String Manipulation, Guess and Check, Approximations, Bisection</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-4-decomposition-abstraction-and-functions">Lecture 4: Decomposition, Abstraction, and Functions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-5-tuples-lists-aliasing-mutability-and-cloning">Lecture 5: Tuples, Lists, Aliasing, Mutability, and Cloning</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-6-recursion-and-dictionaries">Lecture 6: Recursion and Dictionaries</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-7-testing-debugging-exceptions-and-assertions">Lecture 7: Testing, Debugging, Exceptions, and Assertions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-8-object-oriented-programming">Lecture 8: Object Oriented Programming</a></li>
  <li>Lecture 9: Python Classes and Inheritance</li>
  <li>Lecture 10: Understanding Program Efficiency, Part 1</li>
  <li>Lecture 11: Understanding Program Efficiency, Part 2</li>
  <li>Lecture 12: Searching and Sorting</li>
 </ul><br>
 <li>Introduction to Computational Thinking and Data Science</li>
 <ul>
  <li>Lecture 1: Introduction, Optimization Problems</li>
  <li>Lecture 2: Optimization Problems</li>
  <li>Lecture 3: Graph-Theoretic Models</li>
  <li>Lecture 4: Stochastic Thinking</li>
  <li>Lecture 5: Random Walks</li>
  <li>Lecture 6: Monte Carlo Simulation</li>
  <li>Lecture 7: Confidence Intervals</li>
  <li>Lecture 8: Sampling and Standard Error</li>
  <li>Lecture 9: Understanding Experimental Data, Part 1</li>
  <li>Lecture 10: Understanding Experimental Data, Part 2</li>
  <li>Lecture 11: Introduction to Machine Learning</li>
  <li>Lecture 12: Clustering</li>
  <li>Lecture 13: Classification</li>
  <li>Lecture 14: Classification and Statistical Sins</li>
  <li>Lecture 15: Statistical Sins and Wrap-Up</li>
 </ul><br>
 <li>Introduction to Algorithms</li>
 <ul>
  <li>Lecture 1: Algorithmic Thinking, Peak Finding</li>
  <li>Lecture 2: Models of Computation, Document Distance</li>
  <li>Lecture 3: Insertion Sort, Merge Sort</li>
  <li>Lecture 4: Heaps and Heap Sort</li>
  <li>Lecture 5: Binary Search Trees, BST Sort</li>
  <li>Lecture 6: AVL Trees, AVL Sort</li>
  <li>Lecture 7: Counting Sort, Radix Sort, Lower Bounds for Sorting</li>
  <li>Lecture 8: Hashing with Chaining</li>
  <li>Lecture 9: Table Doubling, Karp-Rabin</li>
  <li>Lecture 10: Open Addressing, Cryptographic Hashing</li>
  <li>Lecture 11: Integer Arithmatic, Karatsuba Multiplication</li>
  <li>Lecture 12: Square Roots, Newton's Method</li>
  <li>Lecture 13: Breadth First Search (BFS)</li>
  <li>Lecture 14: Depth First Search (DFS), Topological Sort</li>
  <li>Lecture 15: Single-Source Shortest Paths Problem</li>
  <li>Lecture 16: Dijkstra</li>
  <li>Lecture 17: Bellman-Ford</li>
  <li>Lecture 18: Speeding Up Dijkstra</li>
  <li>Lecture 19: Dynamic Programming I: Fibonacci, Shortest Paths</li>
  <li>Lecture 20: Dynamic Programming II: Text Justification, Blackjack</li>
  <li>Lecture 21: Dynamic Programming III: Parenthesization, Edit Distance, Knapsack</li>
  <li>Lecture 22: Dynamic Programming IV: Guitar Fingering, Tetris, Super Mario Bros.</li>
  <li>Lecture 23: Computational Complexity</li>
  <li>Lecture 24: Topics in Algorithms Research</li>
 </ul><br>
 <li>Design and Analysis of Algorithms</li>
 <ul>
  <li>Lecture 1: Course Overview, Interval Scheduling</li>
  <li>Lecture 2: Divide and Conquer: Convex Hull, Median Finding</li>
  <li>Lecture 3: Divide and Conquer: FFT</li>
  <li>Lecture 4: Divide and Conquer: van Emde Boas Trees</li>
  <li>Lecture 5: Amortization: Amortized Analysis</li>
  <li>Lecture 6: Randomization: Matrix Multiply, Quicksort</li>
  <li>Lecture 7: Randomization: Skip Lists</li>
  <li>Lecture 8: Randomization: Universal and Perfect Hashing</li>
  <li>Lecture 9: Augmentation: Range Trees</li>
  <li>Lecture 10: Dynamic Programming: Advanced DP</li>
  <li>Lecture 11: Dynamic Programming: All-Pairs Shortest Path</li>
  <li>Lecture 12: Greedy Algorithms: Minimum Spanning Tree</li>
  <li>Lecture 13: Incremental Improvement: Max Flow, Min Cut</li>
  <li>Lecture 14: Incremental Improvement: Matching</li>
  <li>Lecture 15: Linear Programming: LP, reductions, Simplex</li>
  <li>Lecture 16: Complexity: P, NP, NP-Completeness, Reductions</li>
  <li>Lecture 17: Complexity: Approximation Algorithms</li>
  <li>Lecture 18: Complexity: Fixed-Parameter Algorithms</li>
  <li>Lecture 19: Synchronous Distributed Algorithms: Symmetry-Breaking, Shortest Paths Spanning Trees</li>
  <li>Lecture 20: Asynchronous Distributed Algorithms: Shortest Paths Spanning Trees</li>
  <li>Lecture 21: Cryptography: Hash Functions</li>
  <li>Lecture 22: Cryptography: Encryption</li>
  <li>Lecture 23: Cache-Oblivious Algorithms: Medians and Matrices</li>
  <li>Lecture 24: Cache-Oblivious Algorithms: Searching and Sorting</li>
 </ul><br>
 <li>Advanced Data Structures</li>
 <ul>
  <li>Lecture 1: Persistent Data Structures</li>
  <li>Lecture 2: Retroactive Data Structures</li>
  <li>Lecture 3: Geometric Data Structures I</li>
  <li>Lecture 4: Geometric Data Structures II</li>
  <li>Lecture 5: Dynamic Optimality I</li>
  <li>Lecture 6: Dynamic Optimality II</li>
  <li>Lecture 7: Memory Hierarchy Models</li>
  <li>Lecture 8: Cache-Oblivious Structures I</li>
  <li>Lecture 9: Cache-Oblivious Structures II</li>
  <li>Lecture 10: Dictionaries</li>
  <li>Lecture 11: Integer Models</li>
  <li>Lecture 12: Fusion Trees</li>
  <li>Lecture 13: Integer Lower Bounds</li>
  <li>Lecture 14: Sorting in Linear Time</li>
  <li>Lecture 15: Static Trees</li>
  <li>Lecture 16: Strings</li>
  <li>Lecture 17: Succinct Structures I</li>
  <li>Lecture 18: Succinct Structures II</li>
  <li>Lecture 19: Dynamic Graphs I</li>
  <li>Lecture 20: Dynamic Graphs II</li>
  <li>Lecture 21: Dynamic Connectivity Lower Bound</li>
  <li>Lecture 22: History of Memory Models</li>
 </ul><br>
 <li>Artificial Intelligence</li>
 <ul>
  <li>Lecture 1: Introduction and Scope</li>
  <li>Lecture 2: Reasoning: Goal Trees and Problem Solving</li>
  <li>Lecture 3: Reasoning: Goal Trees and Rule-Based Expert Systems</li>
  <li>Lecture 4: Search: Depth-First, Hill Climbing, Beam</li>
  <li>Lecture 5: Search: Optimal, Branch and Bound, A*</li>
  <li>Lecture 6: Search: Games, Minimax, and Alpha-Beta</li>
  <li>Lecture 7: Constraints: Interpreting Line Drawings</li>
  <li>Lecture 8: Constraints: Search, Domain Reduction</li>
  <li>Lecture 9: Constraints: Visual Object Recognition</li>
  <li>Lecture 10: Introduction to Learning, Nearest Neighbors</li>
  <li>Lecture 11: Learning: Identification Trees, Disorder</li>
  <li>Lecture 12: Neural Nets</li>
  <li>Lecture 13: Deep Neural Nets</li>
  <li>Lecture 14: Learning: Genetic Algorithms</li>
  <li>Lecture 15: Learning: Sparse Spaces, Phonology</li>
  <li>Lecture 16: Learning: Near Misses, Felicity Conditions</li>
  <li>Lecture 17: Learning: Support Vector Machines</li>
  <li>Lecture 18: Learning: Boosting</li>
  <li>Lecture 19: Representations: Classes, Trajectories, Transitions</li>
  <li>Lecture 20: Architectures: GPS, SOAR, Subsumption, Society of Mind</li>
  <li>Lecture 21: Probilistic Inference I</li>
  <li>Lecture 22: Probilistic Inference II</li>
  <li>Lecture 23: Model Merging, Cross-Modal Coupling, Course Summary</li>
 </ul><br>
 <li>Computer Systems Security</li>
 <ul>
  <li>Lecture 1: Introduction, Threat Models</li>
  <li>Lecture 2: Control Hijacking Attacks</li>
  <li>Lecture 3: Buffer Overflow Exploits and Defenses</li>
  <li>Lecture 4: Privilege Separation</li>
  <li>Lecture 5: Capabilities</li>
  <li>Lecture 6: Sandboxing Native Code</li>
  <li>Lecture 7: Web Security Model</li>
  <li>Lecture 8: Securing Web Applications</li>
  <li>Lecture 9: Symbolic Execution</li>
  <li>Lecture 10: Ur/Web</li>
  <li>Lecture 11: Network Security</li>
  <li>Lecture 12: Network Protocols</li>
  <li>Lecture 13: SSL and HTTPS</li>
  <li>Lecture 14: Medical Software</li>
  <li>Lecture 15: Side-Channel Attacks</li>
  <li>Lecture 16: User Authentication</li>
  <li>Lecture 17: Private Browsing</li>
  <li>Lecture 18: Anonymous Communication</li>
  <li>Lecture 19: Mobile Phone Security</li>
  <li>Lecture 20: Data Tracking</li>
  <li>Lecture 21: Guest Lecture by MIT IS&T</li>
  <li>Lecture 22: Security Economics</li>
 </ul><br>
 <li>Software Design and Architecture Specialization</li>
 <ul>
  <li>Object-Oriented Design</li>
  <ul>
   <li>Lecture 1: Object-Oriented Analysis and Design</li>
   <li>Lecture 2: Object-Oriented Modeling</li>
   <li>Lecture 3: Design Principles</li>
   <li>Lecture 4: Capstone Challenge</li>
  </ul>
  <li>Design Patterns</li>
  <ul>
   <li>Lecture 1: Introduction to Design Patterns: Creational & Structural Patterns</li>
   <li>Lecture 2: Behavioural Design Patterns</li>
   <li>Lecture 3: Working with Design Patterns & Anti-patterns</li>
   <li>Lecture 4: Capstone Challenge</li>
  </ul>
  <li>Software Architecture</li>
  <ul>
   <li>Lecture 1: UML Architecture Diagrams</li>
   <li>Lecture 2: Architectural Styles</li>
   <li>Lecture 3: Architecture in Practice</li>
   <li>Lecture 4: Capstone Challenge</li>
  </ul>
  <li>Service-Oriented Architecture</li>
  <ul>
   <li>Lecture 1: Web Technologies</li>
   <li>Lecture 2: Web Services</li>
   <li>Lecture 3: REST Architecture for SOA</li>
   <li>Lecture 4: Capstone Challenge</li>
  </ul>
 </ul><br>
 <li>Advanced Machine Learning with TensorFlow on Google Cloud Platform Specialization</li>
 <ul>
  <li>End-to-End Machine Learning with TensorFlow on GCP</li>
  <ul>
   <li>Lecture 1: Welcome to the Course</li>
   <li>Lecture 2: Machine Learning (ML) on Google Cloud Platform (GCP)</li> 
   <li>Lecture 3: Explore the Data</li>
   <li>Lecture 4: Create the Dataset</li> 
   <li>Lecture 5: Build the Model</li>
   <li>Lecture 6: Operationalize the Model</li>
   <li>Lecture 7: Course Summary</li>
  </ul>
  <li>Production Machine Learning Systems</li>
  <ul>
   <li>Lecture 1: Welcome to the Course</li>
   <li>Lecture 2: Architecting Production ML Systems</li>
   <li>Lecture 3: Ingesting Data for Cloud-Based Analytics and ML</li>
   <li>Lecture 4: Designing Adaptable ML Systems</li>
   <li>Lecture 5: Designing High-performance ML Systems</li>
   <li>Lecture 6: Hybrid ML Systems</li> 
   <li>Lecture 7: Course Summary</li>
  </ul>
  <li>Image Understanding with TensorFlow on GCP</li>
  <ul>
   <li>Lecture 1: Welcome to Image Understanding with TensorFlow on GCP</li>
   <li>Lecture 2: Linear and DNN Models</li>
   <li>Lecture 3: Convolutional Neural Networks (CNNs)</li>
   <li>Lecture 4: Dealing with Data Scarcity</li>
   <li>Lecture 5: Going Deeper Faster</li>
   <li>Lecture 6: Pre-built ML Models for Image Classification</li>
   <li>Lecture 7: Course Summary</li>
  </ul>
  <li>Sequence Models for Time Series and Natural Language Processing</li>
  <ul>
   <li>Lecture 1: Working with Sequences</li>
   <li>Lecture 2: Recurrent Neural Networks</li>
   <li>Lecture 3: Dealing with Longer Sequences</li>
   <li>Lecture 4: Text Classification</li>
   <li>Lecture 5: Reusable Embeddings</li>
   <li>Lecture 6: Encoder-Decoder Models</li>
   <li>Lecture 7: Course Summary</li>
  </ul>
  <li>Recommendation Systems with TensorFlow on GCP</li>
  <ul>
   <li>Lecture 1: Recommendation Systems Overview</li>
   <li>Lecture 2: Content-Based Recommendation Systems</li>
   <li>Lecture 3: Collaborative Filtering Recommendation Systems</li>
   <li>Lecture 4: Neural Networks for Recommendation Systems</li>
   <li>Lecture 5: Building an End-to-End Recommendation System</li>
   <li>Lecture 6: Course Summary</li>
  </ul>
 </ul>
</ul>

<h1>Introduction to Computer Science and Programming in Python</h1>
<h2>Lecture 1: What is Computation?</h2>
<p>Computers perform built-in and programmer-defined calculations and store results.<br>
Types of Knowledge: Declarative (statement of fact) and Imperative (sequence of steps)<br>
An algorithm is a sequence of steps with a flow of control and a determined stopping point<br>
Basic Machine Architecture: Memory, ALU (primitive operations), Control Unit, Input / Output<br>
Anything computable in one language is computable in every other language<br>
Scalar Object: int, float, complex, bool, bytes, NoneType<br>
Non-Scalar Object: strings, lists, tuples, dictionaries, sets, and user defined classes<br>
You can use type() to find what type the object is. This is helpful in debugging<br></p>
<h2>Lecture 2: Branching and Iteration</h2>
<h2>Lecture 3: String Manipulation, Guess and Check, Approximations, Bisection</h2>
<h2>Lecture 4: Decomposition, Abstraction, and Functions</h2>
<h2>Lecture 5: Tuples, Lists, Aliasing, Mutability, and Cloning</h2>
<h2>Lecture 6: Recursion and Dictionaries</h2>
<h2>Lecture 7: Testing, Debugging, Exceptions, and Assertions</h2>
<h2>Lecture 8: Object Oriented Programming</h2>
<h2>Lecture 9: Python Classes and Inheritance</h2>
<h2>Lecture 10: Understanding Program Efficiency, Part 1</h2>
<h2>Lecture 11: Understanding Program Efficiency, Part 2</h2>
<h2>Lecture 12: Searching and Sorting</h2>
<h1>Introduction to Algorithms</h1>
<h2>Lecture 10: Open Addressing, Cryptographic Hashing</h2>
Open addressing, the simplest way to create a hash table, implements a hash table using a single array, rather than chaining with linked lists. However, to get open addressing hash tables to be efficient, you have to be more careful than when making hash tables with chaining.<br>

<h3>Open Addressing</h3>
<ul>
 <li>Open addressing is a way to implement hash tables without using chaining to deal with collisions</li>
 <li>Open addressing stores keys and values in a single array, with at most one item per slot. This means there are no collisions, and thus no need for chaining</li>
 <ul>
  <li>To ensure no collisions will occur, M, or the number of slots, has to be greater than or equal to N, the number of items
 </ul>
 <li>To ensure the hash function does not collide with another element, open addressing uses probing. Probing alters the hash function and tests slots until it finds one that does not have another key-value pair. Probing is an iterative process</li>
 <ul>
  <li>To do probing, you need a hash function that specifies the order of slots to probe for a key (for insert, search, and delete)</li>
  <li>The hash function takes in the universe of keys (U) and the trial count. Ultimately the hash function produces a number between 0 and M-1</li>
  <li>Probing must ensure that all slots are permutations of 0, 1, ..., M-1; meaning all slots have the ability to be probed by the hash function</li>
 </ul>
 <li>Insertion: while the probing function is working the hash function looks like this: h(100,1) = 4. 100 is the value, 1 is the trial count, and 4 is the slot. If the slot of 4 is already occupied, it then becomes h(100,2) = 7. This continues until it finds an open slot (either DeleteMe or None)</li>
 <li>Search: As long as the slot probed is not equal to the key (k), keep probing until you either encounter k or find an empty slot. Since you are using the same hash probing algorithm that would be used to insert, if it returns None, k does not exist. </li>
 <ul>
  <li>Search treats DeleteMe the same as an incorrect key, instead of None. Therefore it keeps going</li>
 </ul>
 <li>Delete: If you delete an early number and replace it with None, that messes up search. Instead, delete the element, then replace it with a DeleteMe flag, that is different than None. </li>
 </ul>
 <h3>Probing Strategies</h3>
 <ul>
  <li>Linear Probing: h(k,i) = (h'(k)+i) mod M. In other words, the initial hash function is random, however, if the slot is filled, it just adds 1 to the slot until it finds an empty slot. It satisfies permutation; however, clustering occurs</li>
  <ul>
   <li>Clustering is a consecutive group of occupied slots. This is bad for load balancing, as ideally the entire array would be used, rather than just small parts. It ruins the randomness of the hashing algorithm</li>
   <li>The alpha (N/M), or load factor, is log(N) when linear probing is used. Clusters cause the hash table to be O(n) rather than O(1)</li>
 </ul>
 <li>Double Hashing: h(k,i) = (h1(k)+ih2(k)) mod M. h1 and h2 are ordinary hash functions. Double hashing works well compared to linear probing.</li>
 <ul>
  <li>If h2(k) is relatively prime to M, than it satisfies permutation</li>
 </ul>
</ul>
<h3>Uniform Hashing Assumption</h3>
<ul>
 <li>Uniform hashing assumption is that each key is equally likely to have any one of the n factorial permutations as its probe sequence</li>
 <ul><li>You can get close with double hashing, but nobody has discovered a perfect hash function to satisfy this property</li></ul>
 <li>With uniform hashing assumption, you can prove that if alpha is N/M, the cost of operations, such as search, insert, and delete is <= 1 / (1-alpha)</li>
  <li>In practice, when alpha gets to around .5, it is necessary to increase the size of M (add more slots) to ensure the cost of operations remains low. Otherwise, use a chaining table</li>
 <li>Open addressing is less expensive, in terms of memory, than chaining tables, since there is no need to use pointers</li>
</ul>
<h3>Cryptographic Hashing</h3>
<ul>
 <li>Password Storage Problem: How do you store a password with nobody knowing it, including the system's admin?</li>
 <ul>
  <li>One-Way Cryptographic Hash: given h(x) = Q --> The value of the hash, it is very hard to find x. Basically, it compares your hashed login password to the saved hash, rather than your password. If the two hashes don't match, than you can't login.</li>
 </ul>
</ul>
<br>

<h2>Lesson 11: Integer Arithmetic, Karatsuba Multiplication</h2>
