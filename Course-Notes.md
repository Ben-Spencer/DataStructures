<h1>Course Notes</h1>
<h1>Preface</h1>
Courses are available at the following links:
<ul>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016/">Introduction to Computer Science and Programming in Python</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/">Introduction to Computational Thinking and Data Science</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/">Introduction to Algorithms</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/">Design and Analysis of Algorithms</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-851-advanced-data-structures-spring-2012/">Advanced Data Structures</a></li>
 <li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/">Artificial Intelligence</a></li>
</ul>
<br>
<h1>Table of Contents</h1>
<ul>
 <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#introduction-to-computer-science-and-programming-in-python">Introduction to Computer Science and Programming in Python</a></li>
 <ul>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-1-what-is-computation">Lecture 1: What is Computation?</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-2-branching-and-iteration">Lecture 2: Branching and Iteration</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-3-string-manipulation-guess-and-check-approximations-bisection">Lecture 3: String Manipulation, Guess and Check, Approximations, Bisection</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-4-decomposition-abstraction-and-functions">Lecture 4: Decomposition, Abstraction, and Functions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-5-tuples-lists-aliasing-mutability-and-cloning">Lecture 5: Tuples, Lists, Aliasing, Mutability, and Cloning</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-6-recursion-and-dictionaries">Lecture 6: Recursion and Dictionaries</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-7-testing-debugging-exceptions-and-assertions">Lecture 7: Testing, Debugging, Exceptions, and Assertions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-8-object-oriented-programming">Lecture 8: Object Oriented Programming</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-9-python-classes-and-inheritance">Lecture 9: Python Classes and Inheritance</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-10-understanding-program-efficiency-part-1">Lecture 10: Understanding Program Efficiency, Part 1</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-11-understanding-program-efficiency-part-2">Lecture 11: Understanding Program Efficiency, Part 2</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-12-searching-and-sorting">Lecture 12: Searching and Sorting</a></li>
 </ul><br>
 <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#introduction-to-computational-thinking-and-data-science">Introduction to Computational Thinking and Data Science</a></li>
 <ul>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-1-introduction-optimization-problems">Lecture 1: Introduction, Optimization Problems</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-2-optimization-problems">Lecture 2: Optimization Problems</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-3-graph-theoretic-models">Lecture 3: Graph-Theoretic Models</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-4-stochastic-thinking">Lecture 4: Stochastic Thinking</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-5-random-walks">Lecture 5: Random Walks</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-6-monte-carlo-simulation">Lecture 6: Monte Carlo Simulation</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-7-confidence-intervals">Lecture 7: Confidence Intervals</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-8-sampling-and-standard-error">Lecture 8: Sampling and Standard Error</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-9-understanding-experimental-data-part-1">Lecture 9: Understanding Experimental Data, Part 1</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-10-understanding-experimental-data-part-2">Lecture 10: Understanding Experimental Data, Part 2</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-11-introduction-to-machine-learning">Lecture 11: Introduction to Machine Learning</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-12-clustering">Lecture 12: Clustering</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-13-classification">Lecture 13: Classification</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-14-classification-and-statistical-sins">Lecture 14: Classification and Statistical Sins</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-15-statistical-sins-and-wrap-up">Lecture 15: Statistical Sins and Wrap-Up</a></li>
 </ul><br>
 <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#introduction-to-algorithms">Introduction to Algorithms</a></li>
 <ul>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-1-algorithmic-thinking-peak-finding">Lecture 1: Algorithmic Thinking, Peak Finding</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-2-models-of-computation-document-distance">Lecture 2: Models of Computation, Document Distance</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-3-insertion-sort-merge-sort">Lecture 3: Insertion Sort, Merge Sort</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-4-heaps-and-heap-sort">Lecture 4: Heaps and Heap Sort</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-5-binary-search-trees-bst-sort">Lecture 5: Binary Search Trees, BST Sort</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-6-avl-trees-avl-sort">Lecture 6: AVL Trees, AVL Sort</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-7-counting-sort-radix-sort-lower-bounds-for-sorting">Lecture 7: Counting Sort, Radix Sort, Lower Bounds for Sorting</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-8-hashing-with-chaining">Lecture 8: Hashing with Chaining</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-9-table-doubling-karp-rabin">Lecture 9: Table Doubling, Karp-Rabin</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-10-open-addressing-cryptographic-hashing">Lecture 10: Open Addressing, Cryptographic Hashing</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lesson-11-integer-arithmetic-karatsuba-multiplication">Lecture 11: Integer Arithmatic, Karatsuba Multiplication</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-12-square-roots-newtons-method">Lecture 12: Square Roots, Newton's Method</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-13-breadth-first-search-bfs">Lecture 13: Breadth First Search (BFS)</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-14-depth-first-search-dfs-topological-sort">Lecture 14: Depth First Search (DFS), Topological Sort</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-15-single-source-shortest-paths-problem">Lecture 15: Single-Source Shortest Paths Problem</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-16-dijkstra">Lecture 16: Dijkstra</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-17-bellman-ford">Lecture 17: Bellman-Ford</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-18-speeding-up-dijkstra">Lecture 18: Speeding Up Dijkstra</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-19-dynamic-programming-i-fibonacci-shortest-paths">Lecture 19: Dynamic Programming I: Fibonacci, Shortest Paths</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-20-dynamic-programming-ii-text-justification-blackjack">Lecture 20: Dynamic Programming II: Text Justification, Blackjack</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-21-dynamic-programming-iii-parenthesization-edit-distance-knapsack">Lecture 21: Dynamic Programming III: Parenthesization, Edit Distance, Knapsack</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-22-dynamic-programming-iv-guitar-fingering-tetris-super-mario-bros">Lecture 22: Dynamic Programming IV: Guitar Fingering, Tetris, Super Mario Bros.</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-23-computational-complexity">Lecture 23: Computational Complexity</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-24-topics-in-algorithms-research
">Lecture 24: Topics in Algorithms Research</a></li>
 </ul><br>
 <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#design-and-analysis-of-algorithms">Design and Analysis of Algorithms</a></li>
 <ul>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-1-course-overview-interval-scheduling">Lecture 1: Course Overview, Interval Scheduling</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-2-divide-and-conquer-convex-hull-median-finding">Lecture 2: Divide and Conquer: Convex Hull, Median Finding</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-3-divide-and-conquer-fft">Lecture 3: Divide and Conquer: FFT</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-4-divide-and-conquer-van-emde-boas-trees">Lecture 4: Divide and Conquer: van Emde Boas Trees</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-5-amortization-amortized-analysis">Lecture 5: Amortization: Amortized Analysis</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-6-randomization-matrix-multiply-quicksort">Lecture 6: Randomization: Matrix Multiply, Quicksort</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-7-randomization-skip-lists">Lecture 7: Randomization: Skip Lists</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-8-randomization-universal-and-perfect-hashing">Lecture 8: Randomization: Universal and Perfect Hashing</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-9-augmentation-range-trees">Lecture 9: Augmentation: Range Trees</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-10-dynamic-programming-advanced-dp">Lecture 10: Dynamic Programming: Advanced DP</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-11-dynamic-programming-all-pairs-shortest-path">Lecture 11: Dynamic Programming: All-Pairs Shortest Path</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-12-greedy-algorithms-minimum-spanning-tree">Lecture 12: Greedy Algorithms: Minimum Spanning Tree</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-13-incremental-improvement-max-flow-min-cut">Lecture 13: Incremental Improvement: Max Flow, Min Cut</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-14-incremental-improvement-matching">Lecture 14: Incremental Improvement: Matching</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-15-linear-programming-lp-reductions-simplex">Lecture 15: Linear Programming: LP, reductions, Simplex</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-16-complexity-p-np-np-completeness-reductions">Lecture 16: Complexity: P, NP, NP-Completeness, Reductions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-17-complexity-approximation-algorithms">Lecture 17: Complexity: Approximation Algorithms</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-18-complexity-fixed-parameter-algorithms">Lecture 18: Complexity: Fixed-Parameter Algorithms</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-19-synchronous-distributed-algorithms-symmetry-breaking-shortest-paths-spanning-trees">Lecture 19: Synchronous Distributed Algorithms: Symmetry-Breaking, Shortest Paths Spanning Trees</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-20-asynchronous-distributed-algorithms-shortest-paths-spanning-trees">Lecture 20: Asynchronous Distributed Algorithms: Shortest Paths Spanning Trees</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-21-cryptography-hash-functions">Lecture 21: Cryptography: Hash Functions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-22-cryptography-encryption">Lecture 22: Cryptography: Encryption</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-23-cache-oblivious-algorithms-medians-and-matrices">Lecture 23: Cache-Oblivious Algorithms: Medians and Matrices</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-24-cache-oblivious-algorithms-searching-and-sorting">Lecture 24: Cache-Oblivious Algorithms: Searching and Sorting</a></li>
 </ul><br>
 <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#advanced-data-structures">Advanced Data Structures</a></li>
 <ul>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-1-persistent-data-structures">Lecture 1: Persistent Data Structures</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-2-retroactive-data-structures">Lecture 2: Retroactive Data Structures</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-3-geometric-data-structures-i">Lecture 3: Geometric Data Structures I</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-4-geometric-data-structures-ii">Lecture 4: Geometric Data Structures II</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-5-dynamic-optimality-i">Lecture 5: Dynamic Optimality I</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-6-dynamic-optimality-ii">Lecture 6: Dynamic Optimality II</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-7-memory-hierarchy-models">Lecture 7: Memory Hierarchy Models</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-8-cache-oblivious-structures-i">Lecture 8: Cache-Oblivious Structures I</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-9-cache-oblivious-structures-ii">Lecture 9: Cache-Oblivious Structures II</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-10-dictionaries">Lecture 10: Dictionaries</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-11-integer-models">Lecture 11: Integer Models</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-12-fusion-trees">Lecture 12: Fusion Trees</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-13-integer-lower-bounds">Lecture 13: Integer Lower Bounds</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-14-sorting-in-linear-time">Lecture 14: Sorting in Linear Time</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-15-static-trees">Lecture 15: Static Trees</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-16-strings">Lecture 16: Strings</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-17-succinct-structures-i">Lecture 17: Succinct Structures I</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-18-succinct-structures-ii">Lecture 18: Succinct Structures II</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-19-dynamic-graphs-i">Lecture 19: Dynamic Graphs I</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-20-dynamic-graphs-ii">Lecture 20: Dynamic Graphs II</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-21-dynamic-connectivity-lower-bound">Lecture 21: Dynamic Connectivity Lower Bound</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-22-history-of-memory-models">Lecture 22: History of Memory Models</a></li>
 </ul><br>
 <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#artificial-intelligence">Artificial Intelligence</a></li>
 <ul>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-1-introduction-and-scope">Lecture 1: Introduction and Scope</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-2-reasoning-goal-trees-and-problem-solving">Lecture 2: Reasoning: Goal Trees and Problem Solving</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-3-reasoning-goal-trees-and-rule-based-expert-systems">Lecture 3: Reasoning: Goal Trees and Rule-Based Expert Systems</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-4-search-depth-first-hill-climbing-beam">Lecture 4: Search: Depth-First, Hill Climbing, Beam</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-5-search-optimal-branch-and-bound-a">Lecture 5: Search: Optimal, Branch and Bound, A*</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-6-search-games-minimax-and-alpha-beta">Lecture 6: Search: Games, Minimax, and Alpha-Beta</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-7-constraints-interpreting-line-drawings">Lecture 7: Constraints: Interpreting Line Drawings</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-8-constraints-search-domain-reduction">Lecture 8: Constraints: Search, Domain Reduction</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-9-constraints-visual-object-recognition">Lecture 9: Constraints: Visual Object Recognition</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-10-introduction-to-learning-nearest-neighbors">Lecture 10: Introduction to Learning, Nearest Neighbors</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-11-learning-identification-trees-disorder">Lecture 11: Learning: Identification Trees, Disorder</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-12-neural-nets">Lecture 12: Neural Nets</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-13-deep-neural-nets">Lecture 13: Deep Neural Nets</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-14-learning-genetic-algorithms">Lecture 14: Learning: Genetic Algorithms</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-15-learning-sparse-spaces-phonology">Lecture 15: Learning: Sparse Spaces, Phonology</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-16-learning-near-misses-felicity-conditions">Lecture 16: Learning: Near Misses, Felicity Conditions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-17-learning-support-vector-machines">Lecture 17: Learning: Support Vector Machines</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-18-learning-boosting">Lecture 18: Learning: Boosting</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-19-representations-classes-trajectories-transitions">Lecture 19: Representations: Classes, Trajectories, Transitions</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-20-architectures-gps-soar-subsumption-society-of-mind">Lecture 20: Architectures: GPS, SOAR, Subsumption, Society of Mind</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-21-probilistic-inference-i">Lecture 21: Probilistic Inference I</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-22-probilistic-inference-ii">Lecture 22: Probilistic Inference II</a></li>
  <li><a href="https://github.com/Ben-Spencer/Interview-Preparation/blob/master/Course-Notes.md#lecture-23-model-merging-cross-modal-coupling-course-summary">Lecture 23: Model Merging, Cross-Modal Coupling, Course Summary</a></li>
 </ul>
</ul>

<h1>Introduction to Computer Science and Programming in Python</h1>
<h2>Lecture 1: What is Computation?</h2>
<p>Computers perform built-in and programmer-defined calculations and store results.<br>
Types of Knowledge: Declarative (statement of fact) and Imperative (sequence of steps)<br>
An algorithm is a sequence of steps with a flow of control and a determined stopping point<br>
Basic Machine Architecture: Memory, ALU (primitive operations), Control Unit, Input / Output<br>
Anything computable in one language is computable in every other language<br>
Scalar Object: int, float, complex, bool, bytes, NoneType<br>
Non-Scalar Object: strings, lists, tuples, dictionaries, sets, and user defined classes<br>
You can use type() to find what type the object is. This is helpful in debugging<br></p>
<h2>Lecture 2: Branching and Iteration</h2>
<ul>
 <h3>String Concatenation</h3>
 <li>The merging of two or more strings together</li>
 <ul>
  <li>Concatenation is implemented in python using the + operator</li>
  <pre>
  a = "Hello, " + "World!"
  print(a) => Returns Hello, World!</pre>
  <li>When a string and a number are concatenated, an error occurs</li>
  <pre>
   a = "Hello " + 5 => Returns TypeError due to combining string and int</pre>
 </ul>
 <h3>String Comparison</h3>
 <li>Strings can be compared to each other, with A < B < C...</li>
 <pre>
 print("a" < "b") => Returns True </pre>
 <h3>String & Integer Concatenation</h3>
 <li>The merging of a string and an int object together</li>
 <ul>
  <li>In print statement, a comma (,) can be used to concatenate a string and an int. Unlike the string concatenation with the + operator, using a comma adds a space in between the combined objects</li>
  <pre>
   print("Hello",5) => Returns Hello 5</pre>
  <li>Other ways to concatenate an integer and string are as follows:</li>
  <ul>
   <li>Use the str() operation to convert the integer into a string object</li>
   <pre>
   print("Hello " + str(5)) => Returns Hello 5</pre>
   <li>Use the % Operator</li>
   <pre>
   s = "Hello "
   y = 5
   print("%s%s" % (s,y)) => Returns Hello 5</pre>
   <li>Use the format function</li>
   <pre>
   print("{}{}".format("Hello ",5))</pre>
   <li>Use f-Strings</li>
   <pre>
   s = "Hello "
   y = 5
   print(f'{s}{y}')</pre>
 </ul>
 </ul>
 <h3>Receiving Input from Users</h3>
 <li>The input() function in Python always returns a string</li>
 <ul>
  <li>If the input is not a string, such as an int, convert the input string to a different data type using built-in functions</li>
  <pre>
  i = int(input())</pre>
  <li>Sometimes, lists of input are given with spaces in-between. Making the input into a list requires the split() function</li>
  <pre>
  input = 1 2 3 4 5
  input().split(" ") => Returns [1, 2, 3, 4, 5]</pre>
  <li>Assigning two or more inputs is possible as well</li>
  <pre>
  input = 1 2 3
  a,b,c = map(int, input().split(" "))
  print(a) => Returns 1
  print(b) => Returns 2
  print(c) => Returns 3</pre>
 </ul>
 <h3>Other Operators</h3>
 <li>Relational (<, <=, >=, >) and Equality Operators (==, !=) always create a True / False Boolean</li>
 <pre>
 print(1 < 2) => Returns True
 print(1 > 2) => Returns False
 print(1 <= 2) => Returns True
 print(1 >= 2) => Returns False
 print(1 == 2) => Returns False
 print(1 != 2) => Returns True</pre>
 <li>The modulo operator (%) is used to return the remainder of the left operand by the right operand</li>
 <pre>
 print(10%2) => Returns 0
 print(11%2) => Returns 1</pre>
 <h3>Loops</h3>
 <li>If, Elif, and Else statements can be used to create branches within programs</li>
 <pre>
 a = 5
 if a < 1:
    print("A is less than 1")
 elif a > 1 and a < 3:
    print("A is less than 3 but greater than 1")
 else:
    print("A is greater than 3")
 
 => Returns A is greater than 3</pre>
</ul>
<li>While loops are used if the number of iterations is unknown</li>
<pre>
  i = 10
  count = 0
  while i != 0:
      if i % 2 == 0:
          i -= 1
          count += 1
      else:
          i //= 2
          count += 1
  print(count) => Returns 5</pre>
<li>For loops are used if the number of iterations is known</li>
<pre>
 arr = []
 for i in range(1,11):
     arr.append(i)
 print(arr) => Returns [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</pre>
 <li>The break command is used to stop a loop</li>
 <pre>
 var = 7
 while var > 0:              
    print('Current var:', var)
    var = var -1
    if var == 5:
       break
 => Returns Current var: 7
 =>         Current var: 6</pre>
</ul>
<h2>Lecture 3: String Manipulation, Guess and Check, Approximations, Bisection</h2>
<h3>Additional Built-In Functions</h3>
<ul>
 <li>Iterable Object: An object that can be iterated over (I.e. a list, string, array, etc.)</li>
 <li>The len() function returns the length of an iterable object. The object may be a sequence (such as a string, bytes, tuple, list, or range) or a collection (such as a dictionary, set, or frozen set</li>
 <pre>
 print(len("abc")) => Returns 3
 print(len([1,2,3,4,5])) => Returns 5</pre>
 <li>The min() function returns the smallest item in an iterable</li>
 <li>The max() function returns the largest item in an iterable</li>
 <pre>
 print(min([1,5,2,4,3])) => Returns 1
 print(max([1,5,2,4,3])) => Returns 5</pre>
 <li>The abs() function returns the absolute value of a number</li>
 <pre>
 print(abs(1)) => Returns 1
 print(abs(-1)) => Returns 1</pre>
</ul>
<h3>Indexing & Slicing</h3>
<ul>
 <li>Indexing: Access elements in an array by using arr[0]. Index starts at 0 in python, so the end of the array is len(arr)-1</li>
 <pre>
 arr = [1,2,3,4,5]
 print(arr[2]) => Returns 3
 print(arr[0]) => Returns 1</pre>
 <ul>
  <li>Indexing can also be done with negative numbers, starting with -1 at the back of the list</li>
  <pre>
  arr = [1,2,3,4,5]
  print(arr[-1]) => Returns 5
  print(arr[-3]) => Returns 3</pre>
 </ul>
 <li>Slicing[start:stop:step] allows you to return a list of elements</li>
 <pre>
 s = "abcdefgh"
 print(s[3:6]) => Returns def
 print(s[3:6:2]) => Returns df
 print(s[::]) => Returns abcdefgh
 print(s[::-1]) => Returns hgfedcba
 print(s[4:1-2]) => Returns ec</pre>
</ul>
<h3>Mutable Vs. Immutable Objects</h3>
<ul>
 <li>Immutable objects are unable to be altered, without creating a new object</li>
 <ul>
  <li>Objects of built-in types like (int, float, bool, str, tuple, unicode) are immutable</li>
 </ul>
 <li>Mutable objects are able to be altered, without creating a new object</li>
 <ul>
  <li>Objects of built-in types like (list, set, dict) are mutable</li>
  <li>Most custom built classes, like (linked lists, trees, graphs) are mutable</li>
 </ul>
</ul>
<h2>Lecture 4: Decomposition, Abstraction, and Functions</h2>
<h3>Decomposition</h3>
<ul>
 <li>Decomposition is the breaking down of a program into small, self-contained, reusable modules that keep code organized and coherent</li>
 <ul>
  <li>Classes and Functions are examples of decomposition</li>
 </ul>
</ul>
<h3>Abstraction</h3>
<ul>
 <li>Abstraction is the process of hiding extraneous data about an object in order to reduce complexity and increase efficiency</li>
 <ul>
  <li>For example, you know what a projector does, but you don't know how it functions internally</li>
  <li>Abstraction is achievable in programming by writing function specifications and docstrings</li>
  <li>Abstraction is used for black-box testing</li>
 </ul>
</ul>
<h3>Functions</h3>
<ul>
 <li>Functions are blocks of organized, reusable code that perform a single action</li>
 <ul>
  <li>The example function below shows how a function is organized</li>
  <pre>
  def functionName(parameters):
     """DOCSTRING"""
     Function Code
     return [expression]</pre>
  <li>The example function below shows a working function</li>
  <pre>
  def is_even(i):
    """
    Input: i - positive integer
    Output: Returns True if i is even, otherwise False
    """
    return i%2 == 0</pre>
 </ul>
 <li>Functions are objects, like everything else in python. This means that functions can call other functions</li>
 <pre>
  def test():
   """Do Something"""
   test2()
   return [expression]
   <br>
   def test2():
    """Do something else"""
    return [expression]</pre>
</ul>



<h2>Lecture 5: Tuples, Lists, Aliasing, Mutability, and Cloning</h2>




<h2>Lecture 6: Recursion and Dictionaries</h2>
<h2>Lecture 7: Testing, Debugging, Exceptions, and Assertions</h2>
<h2>Lecture 8: Object Oriented Programming</h2>
<h2>Lecture 9: Python Classes and Inheritance</h2>
<h2>Lecture 10: Understanding Program Efficiency, Part 1</h2>
<h2>Lecture 11: Understanding Program Efficiency, Part 2</h2>
<h2>Lecture 12: Searching and Sorting</h2>

<h1>Introduction to Computational Thinking and Data Science</h1>
<h2>Lecture 1: Introduction, Optimization Problems</h2>
<h2>Lecture 2: Optimization Problems</h2>
<h2>Lecture 3: Graph-Theoretic Models</h2>
<h2>Lecture 4: Stochastic Thinking</h2>
<h2>Lecture 5: Random Walks</h2>
<h2>Lecture 6: Monte Carlo Simulation</h2>
<h2>Lecture 7: Confidence Intervals</h2>
<h2>Lecture 8: Sampling and Standard Error</h2>
<h2>Lecture 9: Understanding Experimental Data, Part 1</h2>
<h2>Lecture 10: Understanding Experimental Data, Part 2</h2>
<h2>Lecture 11: Introduction to Machine Learning</h2>
<h2>Lecture 12: Clustering</h2>
<h2>Lecture 13: Classification</h2>
<h2>Lecture 14: Classification and Statistical Sins</h2>
<h2>Lecture 15: Statistical Sins and Wrap-Up</h2>

<h1>Introduction to Algorithms</h1>
<h2>Lecture 1: Algorithmic Thinking, Peak Finding</h2>
<h2>Lecture 2: Models of Computation, Document Distance</h2>
<h2>Lecture 3: Insertion Sort, Merge Sort</h2>
<h2>Lecture 4: Heaps and Heap Sort</h2>
<h2>Lecture 5: Binary Search Trees, BST Sort</h2>
<h2>Lecture 6: AVL Trees, AVL Sort</h2>
<h2>Lecture 7: Counting Sort, Radix Sort, Lower Bounds for Sorting</h2>
<h2>Lecture 8: Hashing with Chaining</h2>
<h2>Lecture 9: Table Doubling, Karp-Rabin</h2>

<h2>Lecture 10: Open Addressing, Cryptographic Hashing</h2>
Open addressing, the simplest way to create a hash table, implements a hash table using a single array, rather than chaining with linked lists. However, to get open addressing hash tables to be efficient, you have to be more careful than when making hash tables with chaining.<br>

<h3>Open Addressing</h3>
<ul>
 <li>Open addressing is a way to implement hash tables without using chaining to deal with collisions</li>
 <li>Open addressing stores keys and values in a single array, with at most one item per slot. This means there are no collisions, and thus no need for chaining</li>
 <ul>
  <li>To ensure no collisions will occur, M, or the number of slots, has to be greater than or equal to N, the number of items
 </ul>
 <li>To ensure the hash function does not collide with another element, open addressing uses probing. Probing alters the hash function and tests slots until it finds one that does not have another key-value pair. Probing is an iterative process</li>
 <ul>
  <li>To do probing, you need a hash function that specifies the order of slots to probe for a key (for insert, search, and delete)</li>
  <li>The hash function takes in the universe of keys (U) and the trial count. Ultimately the hash function produces a number between 0 and M-1</li>
  <li>Probing must ensure that all slots are permutations of 0, 1, ..., M-1; meaning all slots have the ability to be probed by the hash function</li>
 </ul>
 <li>Insertion: while the probing function is working the hash function looks like this: h(100,1) = 4. 100 is the value, 1 is the trial count, and 4 is the slot. If the slot of 4 is already occupied, it then becomes h(100,2) = 7. This continues until it finds an open slot (either DeleteMe or None)</li>
 <li>Search: As long as the slot probed is not equal to the key (k), keep probing until you either encounter k or find an empty slot. Since you are using the same hash probing algorithm that would be used to insert, if it returns None, k does not exist. </li>
 <ul>
  <li>Search treats DeleteMe the same as an incorrect key, instead of None. Therefore it keeps going</li>
 </ul>
 <li>Delete: If you delete an early number and replace it with None, that messes up search. Instead, delete the element, then replace it with a DeleteMe flag, that is different than None. </li>
 </ul>
 <h3>Probing Strategies</h3>
 <ul>
  <li>Linear Probing: h(k,i) = (h'(k)+i) mod M. In other words, the initial hash function is random, however, if the slot is filled, it just adds 1 to the slot until it finds an empty slot. It satisfies permutation; however, clustering occurs</li>
  <ul>
   <li>Clustering is a consecutive group of occupied slots. This is bad for load balancing, as ideally the entire array would be used, rather than just small parts. It ruins the randomness of the hashing algorithm</li>
   <li>The alpha (N/M), or load factor, is log(N) when linear probing is used. Clusters cause the hash table to be O(n) rather than O(1)</li>
 </ul>
 <li>Double Hashing: h(k,i) = (h1(k)+ih2(k)) mod M. h1 and h2 are ordinary hash functions. Double hashing works well compared to linear probing.</li>
 <ul>
  <li>If h2(k) is relatively prime to M, than it satisfies permutation</li>
 </ul>
</ul>
<h3>Uniform Hashing Assumption</h3>
<ul>
 <li>Uniform hashing assumption is that each key is equally likely to have any one of the n factorial permutations as its probe sequence</li>
 <ul><li>You can get close with double hashing, but nobody has discovered a perfect hash function to satisfy this property</li></ul>
 <li>With uniform hashing assumption, you can prove that if alpha is N/M, the cost of operations, such as search, insert, and delete is <= 1 / (1-alpha)</li>
  <li>In practice, when alpha gets to around .5, it is necessary to increase the size of M (add more slots) to ensure the cost of operations remains low. Otherwise, use a chaining table</li>
 <li>Open addressing is less expensive, in terms of memory, than chaining tables, since there is no need to use pointers</li>
</ul>
<h3>Cryptographic Hashing</h3>
<ul>
 <li>Password Storage Problem: How do you store a password with nobody knowing it, including the system's admin?</li>
 <ul>
  <li>One-Way Cryptographic Hash: given h(x) = Q --> The value of the hash, it is very hard to find x. Basically, it compares your hashed login password to the saved hash, rather than your password. If the two hashes don't match, than you can't login.</li>
 </ul>
</ul>
<br>

<h2>Lecture 11: Integer Arithmetic, Karatsuba Multiplication</h2>
A CPU, or central processing unit, takes instructions from a program or applicaton and performs a calculation. The instruction set, taken by the CPU, comes in <b>words</b>, or fixed-sized pieces of data. The most common word-size today is 64 bits. So, what happens if you can't store all the data in one word? What happens if you have to multiply words that are thousands of bits long? That's the purpose of this lecture.<br>
<h3>Irrationals</h3>
<ul>
 <li>The pythagorean theorem, or A^2 + B^2 = C^2, leads to irrational numbers. If A and B are both size 1, C is sqrt(2)</li>
 <li>Newton's Method: A root-finding algorithm that results in quadratic convergence of approximations around the root.</li>
  <ul>
   <li>Root: When the function attains the value of 0. (I.e. F(x) = x + 1 is 0 at x = -1)</li>
   <li>Root-finding algorithm: An algorithm that finds the root of a function</li>
   <li>Quadratic Convergence: Every new approximation of the root-finding algorithm results in 2X more decimals. For example, n(1) = 2; n(2) = 1.5; n(3) = 1.463; n(4) = 1.4628916</li>
   <li>Newton's method equation: Xn+1 = Xn - (f(Xn) ÷ f'(Xn))</li>
   <ul>
    <li>X0 is the first approximation. The equation for X1 is: X1 = X0 - (f(X0) ÷ f'(X0))</li>
  </ul>
 </ul>
 <li>Catalan Numbers, or (2n)! ÷ ((2n+1)! * n!), can be solved recursively</li>
   
</ul>
<h3>Karatsuba Multiplication</h3>
<ul>
 <li>Karatsuba is faster than normal division. It's O(N^lg3), while normal division is O(N^2)</li>
 <li>T(N) = 3T(N/2) + O(N)</li>
</ul>

<h2>Lecture 12: Square Roots, Newton's Method</h2>
<h3>Review</h3>
<ul>
 <li>The goal is to get the millionth digit of sqrt(2)</li>
 <ul>
  <li>To compute this, work with integers: Floor(sqrt(2 * 10^(2d)). d is the number of digits of precision. Therefore, d = 6</li>
  <li>Compute Floor(sqrt(a)) via Newton's method</li>
  <ul>
   <li>Newton's method works by iteratively approximating the slope of the line</li>
   <li>X0 = 1 (initial guess); Xi+1 = (Xi + a/Xi)/2</li>
   <li>Newton's method has a quadratic rate of convergence, meaning the number of correct digits multiplies by 2 every iteration</li>
  </ul>
 </ul>
</ul>
<h3>Error Analysis of Newton's Method</h3>
<ul>
 <li>Xn = sqrt(a)*(1+En) in which En may be + or -. En, as Xn becomes large, approaches 0</li>
 <li>Xn+1 = sqrt(a)*((1+En^2)/(2*(1+En)). Therefore, En+1 = (En^2 / 2*(1+En))</li>
 <li>This proves that Newton's method indeed has a quadratic rate of convergence</li>
 <li>Therefore, to get to (d) digits, it takes log(d) iterations</li>
</ul>
<h3>Multiplication Algorithms</h3>
<ul>
 <li>Want to multiply (d) digit algorithms</li>
 <ul>
  <li>The naive divide and conquer way to do this provides O(n^2) complexity</li>
  <li>Using karatsuba multiplication, it is possible to get O(n^1.58) complexity</li>
  <li>The Toom-Cook method takes karatsuba multiplication and divides it into multiple parts. Toom-3 takes O(n^1.465) complexity</li>
  <li>Schönhege-Strassen method of multiplication takes O(n lgn lglgn) time using FFT</li>
  <li>Python gmpy package can be used to experiment with the different multiplication methods</li>
  <li>Furer method takes O(n logn 2^O(log*n)) in which O(log*n) is an iterated logarithm which is # of times log needs to be applied to get a result that is less than or equal to 1</li>
 </ul>
</ul>
<h3>High-Precision Division</h3>
<ul>
 <li>We want a high-precision rep of A divided by B</li>
 <ul>
  <li>To get this, we first get a high-precision rep of 1/B</li>
  <ul>
   <li>To get 1/B, we need to compute Floor(R/B) in which R is a large, easy-to-divide value</li>
   <li>Use Newton's method to compute R/B; using the equation f(x) = (1/x) - (B/R) => This yields a 0 at R/B</li>
   <li>Plugging it in to Newton's method gives the equation 2Xi - (BXi^2 / R)</li>
   <li>Newton's method is quadratic convergence for both multiplication and division</li>
  </ul>
 </ul>
 <li>Since division is quadratic convergence, to get (d) digits of precision, it takes log d iterations</li>
 <li>Therefore, division is O(log n n^ā) in which ā is ≥ 1</li>
 <li>The above complexity is high, as division uses quadratic rate of convergence</li>
 <li>The actual complexity is O(2C*n^ā), or O(n^ā) which is the same as multiplication</li>
 <li>That means the complexity of computing square roots is also O(n^ā)</li>
</ul>

<h2>Lecture 13: Breadth First Search (BFS)</h2>
Graph search is about exploring a graph. Both finding the shortest path from one node to another and finding all end potential end points, are exploration problems. 
<h3>Graph Composition Recap</h3>
<ul>
 <li>Graphs are composed of a set of vertices (V) and a set of edges (E)</li>
 <ul>
  <li>Edges are either unordered/undirected {v,w} or ordered/directed (v,w). Usually, there is only one type present in a given graph problem</li>
 </ul>
 <li>Example: Undirected: Vertices = {a,b,c,d}; Edges = {{a,b}, {a,c}, {b,c}, {b,d}, {c,d}}</li>
 <li>Example: Directed: Vertices = (a,b,c); Edges = {(a,c), (b,c), (c,b), (b,a)}</li>
</ul>
<h3>Uses of Graph Search</h3>
<li>Web crawling, social networking, network broadcast, garbage collection, model checking, puzzles / games</li>
<h3>Pocket Rubix Cube: 2 x 2 x 2</h3>
<ul>
 <li>Verticies: 8! * 3^8 potential verticies. This includes every possible configuration of the cube</li>
 <li>Edges can move in either direction, so they are undirected</li>
 <li>Takes 11 moves to complete the cube from any state. This is found by doing breadth-first search (traversing a graph layer by layer)</li>
 <li>For 3x3x3, it takes 20 moves to complete the cube</li>
 <li>For NxNxN, it is approximately O(n^2 / log n)</li>
</ul>
<h3>Graph Representation</h3>
<ul>
 <li>Adjacency Lists: Array (Adj) of size V (length of verticies), with each element of the array being a pointer to a linked list</li>
 <ul>
  <li>For each vertex, u ∈ V, Adj(u) stores u's neighbors. This means the verticies you can reach are one layer down from each node</li>
  <ul>
   <li>Adj(u) is the set of all verticies (V) such that (u, v) is an edge</li>
   <li>Adjacency Lists are O(V+E) in terms of run-time</li>
  </ul>
  <li>Example: From the directed graph above, Adj(a) = {c}; Adj(b) = {a, c}; Adj(c) = {b}</li>
 </ul>
 <li>Object-Oriented Graphs: v.neighbors = Adj[u]</li>
 <ul>
  <li>Used if only one graph. Use adjacency lists if multiple uses for same verticies. Is cleaner than adjacency lists</li>
 </ul>
 <li>Implicitly represented graphs: Adj[u] is a function; v.neighbors is a method of the class Vertex</li>
 <ul>
  <li>This means you don't store any neighbors, but rather have an equation that computes neighbors. Requires potentially 0 storage for individual verticies</li>
  <li>This method would be used for Rubix cubes because you don't have to store 264,000,000+ (for a 2x2x2) different nodes</li>
 </ul>
</ul>
<h3>Breadth-First Search</h3>
<ul>
 <li>Visit all nodes reachable from a given node(S) in O(V+E) time by looking at nodes reachable in 0 moves, 1 moves, 2 moves...</li>
 <li>Be careful to avoid duplicate or revisiting verticies, as this would cause an infinite loop</li>
 <pre>
 # Breadth-First-Search Pseudocode
 def BFS(s, Adj):
  level = {S:0} #S is the starting node. Its level is 0, as it takes 0 moves to get from S to S
  parent = {S:None} #Since S is the starting node, it has no parent
  i = 1 #Set to 1 because just finished level 0 - identifying the start node
  frontier = [S] #all the things you can reach using i-1 moves; set to S because S is what is reached at level 0
  while frontier: #all the things you can reach using i moves
   next = []
   for u in frontier: #for all nodes in the current frontier...
    for v in Adj[u]: #find all nodes reachable by each vertice...
     if v not in level: #and check to avoid duplicates, by checking to see if its in the dictionary
      level[v] = i #if its not in dict, add to dict
      parent[v] = u #create a pointer to the parent of each vertice and add to dictionary
      next.append(v) #append to next level
   frontier = next #set frontier to the next level
   i+=1 #increment the while loop
 </pre>
 <li>If you follow parents all the way back, it will return the shortest path from a node to the starting (S) node</li>
 <ul>
  <li>The shortest path length will be equivalent to level[v]</li>
 </ul>
</ul><br>

<h2>Lecture 14: Depth First Search (DFS), Topological Sort</h2>
Input for each vertex is the neighbor verticies, that can be reached in one step via an edge. Goal in general is to explore a graph. 
Visit all the verticies in a specific order, only once. 
DFS is used to explore the whole graph, rather than just the nodes reachable by the root node (s)

<h3>Depth First Search</h3>
<ul>
 <li>Depth-First Search is the recursive exploration of a graph, backtracking when necessary and ensuring not to repeat verticies</li>
</ul>
<pre>
parent = { s: None } #Setting up the parent node in the dictionary
Dfs-Visit(V, Adj,s): #Visit all of the verticies surrounding a parent node (s)
 for V in Adj[s]: #check for all verticies adjacent to (s)
  if V not in parent: #check to see if vertice is already in dictionary; if not...
   parent[V] = s #add the vertice to dictionary of seen verticies
   Dfs-Visit(V,Adj,s) #call Dfs-Visit until there are no more unseen verticies</pre>
<pre>
DFS(V, Adj): #Visit all verticies
parent = {} #Parent stores seen elements
for s in V:
 if s not in parent: #If the element has not been seen
  parent[s] = None
  Dfs-Visit(V, Adj, s) #Find all verticies of the element</pre>
<ul>
 <li>Time complexity is O(V+E)</li>
 <ul>
  <li>The reason for this is you visit every vertex and edge once throughout the algorithm</li>
 </ul>
</ul>
<h3>Edge Classification</h3>
<ul>
 <li>Tree edges: An edge that leads to an unvisited vertice</li>
 <li>Forward edges: An edge that extends from a parent to a visited child vertice</li>
 <li>Backward edges: An edge from a child that extends to a parent vertice</li>
 <li>Cross edges: An edge between non-ancestors</li>
<br>
 <li>In undirected graphs, only tree edges and backward edges can exist, not forward or cross edges</li>
 <li>Edges are useful for cycle-detection and topological sort</li>
 <li>Graph G has a cycle if and only if Depth-First Search of G has a back edge</li>
</ul>
<h3>Topological Sort</h3>
<ul>
 <li>Job Scheduling Problem: Given a directed acyclic graph (DAG). Want to order the verticies so that all edges point from lower order to higher order</li>
 <li>Run Depth-First Search and output the reverse of finishing times of verticies</li>
 <li>This works because DFS completes in-order, so by reversing that order you go from lower order to higher orders</li>
 <li>Since topological sort uses DFS, it has a linear runtime, O(V+E)</li>
</ul>
 
<h2>Lecture 15: Single-Source Shortest Paths Problem</h2>
<ul>
 <li>Motivation for shortest path is to find the fastest way from getting from one location to another</li>
 <li>For the next few lectures, we're going to be trying to minimize the computational complexity of G(V,E,W) -> Graph(verticies, edges, weights)</li>
 <li>Two algorithms will be covered:</li>
 <ul>
  <li>Dijkstra's Algorithm: O(V log(V+E)). Dijkstra's algorithm is dominated by E and only works with positive edges</li>
  <li>Bellman-Ford Algorithm: O(VE). Works with both positive and negative edges</li>
 </ul>
 <li>Path P is a sequence of verticies <v0, v1, ..., vk> in which (Vi, Vi+1) is contained in edges for 0 ≤ i < k</li>
 <li>The weight of the path [W(p)] is the summation of the weight of traversed edges</li>
 <li>The shortest path problem tries to find the path with the minimum weight</li>
 <li>W, in the given parameters, does not exist in the complexity of both Dijkstra's and Bellman-Ford algorithms</li>
 <li>If the shortest path doesn't exist, as in there is no connection between the start and end node, the path is infinity</li>
 <li>Inside each node, track two things, predacessor node and the current weight to get to the node</li>
 <li>The predacessor node allows you to return the shortest path, and the current weight allows you to see the weight of the shortest path</li>
 <li>Negative weights can be used to demonstrate reverse tolls and social networks. Dijkstra's algorithm does not work with negative weights, however, Bellman-Ford algorithm does</li>
 <li>If there is a cycle that has a negative weight, for example, [1,4,-6], then there is the potential to create an infinite loop</li>
 <li>Bellman-Ford fixes this by outputing every number not affected by the negative loop, then marking the negative loops as negative infinity</li>
  <li>Relaxation is a method of comparing the current weight of a node to the potential weight of the same node. If the new weight is less than the old weight, than the old weight is replaced by the new weight. Otherwise, nothing changes</li>
  <li>Optimal Substructure: Subpaths of a shortest path are shortest paths</li>
</ul>

<h2>Lecture 16: Dijkstra</h2>
<h3>Review</h3>
<ul>
 <li>The numbers inside the vertices are priority values, or the length of the current shortest path from the source S to V</li>
 <li>Initially, S has a priority value of 0 and all other vertices have priority values of infinity</li>
 <li>The delta value of S to V is the length of the shortest path</li>
 <li>π[V] is the predacessor of V in the shortest path from S to V. Follow the predacessor chain back to create the shorest path</li>
</ul>
<h3>Relaxation</h3>
<ul>
 <pre>
 def Relax(u, v, w):
  if d[v] > d[u] + w[u,v]:
   d[v] = d[u] + w[u,v]
   π[v] = u</pre>
 <li>Relaxation is safe, the lemma below says that there is no way to get a lower delta than d value</li>
 <li>Lemma: The relaxation operation maintains the invariant that d[v] ≥ delta(s,v) for v ∈ V</li>
 <li>The triangle inequality says that it is not possible to have a shorter delta(s,u); delta(u,v) than just delta(s,v) becuase delta(s,v) is by definition the shortest path between s and v</li>
</ul>
<h3>Directed Acyclic Graphs (DAGs)</h3>
<ul>
 <li>Can't have cycles (or negative cycles)</li>
 <li>Allowed to have both positive and negative edges</li>
 <li>1) Topological sort the DAG, the path from u to v implies that u is before v in the ordering</li>
 <li>2) One pass over verticies in topologically sorted order relaxing each edge that leaves each vertex</li>
 <li>DAG special case shortest path algorithm is O(V+E) time</li>
 <li>DAGs can always be drawn in a straight line, as there are no cycles</li>
</ul>
<h3>Dijkstra's Algorithm</h3>
<pre>
Dijkstra(g, w, s): => g is a graph, w is the weights, s is the starting vertex
 Initialize (g,s) => Mark s as the starting vertex; d[s] = 0
 S is a set with the value null
 Q is a set with the entire set of verticies; Q is a priority queue in which the priorities are d() values
 While Q != Null:
  u <- Extract min from Q (deletes u from Q)
  for each vertex for each adjacent u:
   Relax(u,v,w)</pre>
<li>Dijkstra's algorithm is greedy, becuase the extract-min step</li>
<li>In other words, it starts with a breadth-first search from the starting node. Then it compares all the values and chooses the minimum. Next, it does breadth-first search from the second vertice, etc.</li>
<li>Using an array to implement the priority queue makes Dijkstra's O(V^2)</li>
<li>Using a binary min-heap to implement the priority queue makes Dijkstra's O(VlgV + ElgV)</li>
<li>Using a fibonacci heap to implement the priority queue makes Dijkstra's O(VlgV + E)</li>
</ul>
<h2>Lecture 17: Bellman-Ford</h2>
<ul>
 <li>Bellman-Ford algorithm is able to find the shortest path with any type of graph, including those with negative cycles</li>
 <li>If there is a negative cycle present in the graph, Bellman-Ford marks it, and every following vertex, as undefined or negative infinity</li>
</ul>
<h3>Generic Shortest Path Algorithm</h3>
<ul>
 <li>Description of Generic S.P. Algorithm</li>
 <ul>
  <li>for v ∈ V, set all d[v] values in the graph to infinity; π(v) to nil</li>
  <li>d[s] = 0; as its your source</li>
  <li>Select an edge [somehow]</li>
  <li>Relax Edge(u,v,w)</li>
  <li>Continue until you can't relax edges anymore</li>
 </ul>
 <li>Two problems with Generic S.P. Algorithm</li>
 <ul>
  <li>Complexity could be exponential time (even for + edge weights)</li>
  <ul>
   <li>Dijkstra's Fixes this first problem</li>
  </ul>
  <li>Algorithm will not terminate if there is a negative weight cycle, reachable from the source</li>
  <ul>
   <li>Bellman-Ford was designed to fix this issue</li>
 </ul>
  <li>Polynomial time is great, exponential time is bad, infinite time gets you fired</li>
 </ul>
</ul>
<h3>Bellman-Ford Implementation</h3>
<pre>
Bellman-Ford(G,W,S): => graph, weights, source
 Initialize() => same as the generic case
 for i = 1 to v - 1:
  for each edge (u,v) ∈ E: => For each edge from vertex U to V contained within the list of edges
   Relax(u,v,w) => Perform relaxation on vertecies
  for each edge (u,v) ∈ E:
   if d[v] > d[u] + w[u,v]:
    report negative cycle exists</pre>
<ul>
<li>Bellman-Ford is O(VE)</li>
<li>This means that if you have the chance to use Dijkstra's Algorithm, use that because it is linear, when using fibonacci heap for the priority queue</li>
</ul>
<h3>Bellman-Ford Proof</h3>
<ul>
 <li>Theorem: If G=(V,E) contains no negative weight cycles, then after Bellman-Ford finishes execution, d[v] = delta(s,v) for all v ∈ V</li>
 <ul>
  <li>Path P (V0, V1, V2..., Vk). k must be ≤ |V| - 1, otherwise there is a cycle. |V| is the total number of vertecies</li>
  <li>Proof by induction: Let v be any Vertex (v ∈ V), p <v0,v1,v2,...,vk>, v0 = s; vk = V</li>
  <li>This path P is a shortest path with min # of edges</li>
  <li>No negative weight cycles implies that P is simple, which implies that vk ≤ |V|-1</li>
  <li>After one pass through all edges E, we have d[v1] = delta[s,v1] because we will relax the edge (v0, v1) during the pass</li>
  <li>After two passes, we have d[v2] = delta[s,v2] because we will relax the edge (v1, v2) during the pass</li>
  <li>After k passes, we have d[vk] = delta[d,vk] beacause if you run through |v|-1 passes, all reachable vertices have delta values</li>
 </ul>
 <li>Corollary: If a value d[v] fails to converge after v-1 passes, there exists a negative weight cycle, reachable from s</li>
 <ul>
  <li>After |v|-1 passes, we find an edge that can be relaxed. This means the current shortest path from s to some vertex is not simple. Therefore, there must be a repeated vertex, or some cycle.</li>
  <li>This cycle has to be a negative cycle, because you are still able to relax the vertecies</li>
 </ul>
</ul>

<h2>Lecture 18: Speeding Up Dijkstra</h2>
<h3>Types of Shortest Path Problems</h3>
<ul>
 <li>Single-Source, Single-Target</li>
 <li>Single-Source to All Destinations</li>
 <li>All-Pair Shortest Path</li>
</ul>
<h3>Dijkstra Pseudocode</h3>
<pre>
Initialize() <- d[s] = 0; d[u≠s] = ∞
Q <- V[a]
while Q ≠ 0:
 Do Q <- Extract the minimum priority of Q
 For each vertex, such that V is a part of Adj[u]
 Relax(u, v, w) ->  π[v] <- u; d[v]=-1;
 
 *Stop if u == t</pre>
<h3>Bidirectional Search</h3>
<ul>
 <li>Source (s) and Target (t) are given. Alternate a forward search from s and a backward search from t (while following edges backward). Do one level at a time.</li>
 <li>Two min-priority queues are needed for bidirectional search, one for each direction</li>
 <li>df[u] is the distances for the forward search; πf is normal predecessor</li>
 <li>db[u] is the distances for the backward search; πb is backward predecessor</li>
 <li>The termination condition occurs when some vertex (u) has been processed both in the forward search and the backward search, and extracted from both priority queues (Qf and Qb)</li>
 <li>Theory: The shortest path is found by using the extracted vertex (W) as a stopping point for πf and a starting point for πb. Both paths extend from u back through the predecessors and ultimately give the shortest path between s and t</li>
 <ul>
  <li>ABOVE IS WRONG: W may not be on the shortest path. Therefore, while the termination condition is correct, it must be augmented to yield the shortest path</li>
  <li>The correct shortest path is done by finding a vertex (x) that isn't necessarily w, that is the minimum value of df[x]+db[x]</li>
  <ul>
   <li>Replace the W in the theory with the vertex (x)</li>
  </ul>
</ul>
<h3>Heuristic Graph Modifications</h3>
<ul>
 <li>Goal Directed Search: Modify edge weights with potential functions</li>
 <li>w'(u,v) = w(u,v) - λ(u) + λ(v)</li>
 <li>Basically, you want to create a downhill gradient towards the target vertex by increasing the potential of vertecies in the incorrect direction and decreasing the weights of verticies in the correct direction. This makes dijkstra's run faster</li>
 <li>Any path w'(p) = w(p) - λt(s) + λt(t)</li>
 <li>Don't alter any shortest paths, what is currently the shortest path should remain the shortest path, regardless of potential weight alterations</li>
 <li>Landmarks can be used to help find the potential weight alterations</li>
</ul>

<h2>Lecture 19: Dynamic Programming I: Fibonacci, Shortest Paths</h2>
<h3>Dynamic Programming</h3>
<ul>
 <li>Dynamic programming (DP) is a general, very powerful algorithm design technique</li>
 <li>DP is especially good at, and intended for optimization problems, such as shortest path (Dijkstra's)</li>
 <li>DP is an exhaustive search, which can achieve results in polynomial (P) time. It is a "careful brute force"</li>
 <li>It's called dynamic programming, because Bellman (the same guy from the Bellman-Ford algorithm) tried to hide mathematical research under a cool name to receive funding</li>
</ul>
<h3>Fibonacci Numbers with DP</h3>
<ul>
 <li>Take a problem, split it into subproblems, solve the subproblems, then reuse the solution to subproblems</li>
 <li>Fibonacci Number Equation: F1 = F2 = 1; Fn = Fn-1 + Fn-2</li>
 <li>Naive Recursive Algorithm</li>
 <pre>
 fib(n):
  if n <= 2:
   f = 1
  else:
   f = fib(n-1) + fib(n-2)
  return f</pre>
 <li>This algorithm results in exponential time, so it's not a good algorithm</li>
 <li>Memoized Dynamic Programming Algorithm</li>
 <pre>
 memo = {}
 fib(n):
  if n in memo:
   return memo[n]
  if n <= 2:
   f = 1
  else:
   f = fib(n-1) + fib(n-2)
  return f</pre>
  <li>Memoization can be used in any recursive algorithm, and it essentially causes memoized calls instead of recursive calls, which cost constant time</li>
  <li>The number of non-memoized calls is n, therefore, DP for fibonacci is O(n)</li>
  <li>Memoization is called that because its like a memo pad where you write in the dictionary</li>
</ul>
<h3>General Dynamic Programming</h3>
<ul>
 <li>Dynamic Programming uses memoization to remember and re-use solutions to subproblems that help solve the problem</li>
 <li>Therefore, dynamic programming can be thought of as recursion + memoization</li>
 <li>The running time of all DP is the # of subproblems * the amount of time spent per subproblem</li>
</ul>
<h3>Bottom-Up DP Algorithm</h3>
<pre>
memo = {}
for k in range(1,n+1):
 if k <= 2: 
  f = 1
 else:
  f = memo[k-1] + memo[k-2]
  memo[k] = f
 return memo[n]</pre>
 <ul>
  <li>The above algorithm yields the exact same results as the previous memoized dynamic programming recursive algorithm, except, it is likely better in practice due to using iterations rather than recursive function calls</li>
  <li>What is happening is actually a topological sort of a subproblem dependency Directed Acyclic Graph (DAG)</li>
  <li>Storage space can be saved by using a bottom-up DP algorithm</li>
 </ul>
<h3>Shortest Paths</h3>
<ul>
 <li>Single source shortest path: delta(s,v) for all V</li>
 <li>Guessing should be used if the answer is unknown. In dynamic programming, try all possible guesses and then choose the best one</li>
 <ul>
  <li>That's why dynamic programming is often used for optimization problems (finding min or max). You try all the answers and then conclude with the best</li> 
 </ul>
 <li>Given a graph with a source (s) and a target vertex (v), find the shortest path between the two</li>
 <li>To do this, guess all the last edges (u) coming from v and check if there is a path from u to s</li>
 <li>Therefore, delta(s,v) = min(delta(s,u) + delta(u,v))</li>
 <li>This algorithm works, but is terrible as the time complexity is exponential</li>
 <li>To improve it, add memoization, storing the delta(s,u) in a dictionary</li>
 <li>For DAGs it runs in O(V+E) time</li>
 <li>However, this algorithm will never finish if there is a cycle in the graph</li>
 <li>To fix this, layer the graph so there are no more cycles. Then it is a DAG, but the number of vertex's is squared; thereby taking exponential v time</li>
</ul>
</ul>

<h2>Lecture 20: Dynamic Programming II: Text Justification, Blackjack</h2>
<h3>Review</h3>
<ul>
 <li>Dynamic Programming is a "careful brute force" methodology, that tries every solution intelligently</li>
 <li>Dynamic Programming is a combination of guessing, recursion, and memoization</li>
 <li>Dynamic Programming is always computing a shortest path in a DAG, even if it doesn't look like it</li>
 <li>Time = # of subproblems * time / subproblem (treat all recursive calls as O(1), due to memoization)</li>
</ul>
<h3>5 "Easy" Steps to Dynamic Programming</h3>
<ul>
 <li>1. Define Subproblems</li>
  <ul>
   <li># of subproblems (n for fibonacci, V^2 for shortest path)</li>
  </ul>
 <li>2. Guess (part of the solution)</li>
 <ul>
   <li># of choices for the guess (1 for fibonacci, indegree(v) +1 for shortest path)</li>
  </ul>
 <li>3. Relate subproblem solutions with recurrance</li>
 <ul>
   <li>Time per Subproblem</li>
  </ul>
 <li>4. Build an algorithm (recursion & memoization or bottom-up approach)</li>
 <ul>
   <li>Check subproblem recurrance is acyclical (i.e. has topological order)</li>
   <li>Total time is found</li>
  </ul>
 <li>5. Combine subproblems to solve the original problem</li>
</ul>
<h3>Text Justification</h3>
<ul>
 <li>Split text into "good" lines</li>
 <li>Text is a list of words</li>
 <li>Badness(i,j) => while i -> j are a line [2 cases: 1. if they don't fit the answer is infinity; 2. if they do fit, the answer is page width - total width ^3]</li>
 <li>The goal is to minimize the badness of all the lines. Greedy strategies would work for packing in as many words as possible, but later lines may look bad as extra spaces must be used. Therefore, this problem is better solved with dynamic programming</li>
 <li>1. Subproblem: suffix words [i:], since all the words starting after the last word in the first line remain</li>
 <li>2. Guess: which word should the second line start? (O(n))</li>
 <li>3. Recurrance: min(DP[i] for j in range(i+1, n+1)) [where i is the first word in the first line and j is the first word of the second line] (O(n))</li>
 <li>4. Topological Order: Work from the end backwards; i = n, n-1, ..., 0; total time = O(n^2)</li>
 <li>5. Solve Problem: DP(0) is solved</li>
 <li>Parent Pointers: Remember which guess was best</li>
 <li>Figuring out what to guess and what your subproblem is are the hardest part of dynamic programming, the rest is automatic</li>
</ul>
<h3>Blackjack</h3>
<ul>
 <li>Given a deck with c0, c1, ..., c-1 cards; 1 player vs dealer; $1 bet per hand; should you hit or stand</li>
 <li>1. Subproblem: Suffix c[i:] of the cards (# of subproblems is n)</li>
 <li>2. Guess: How many times should you hit in the first play? (# of choices ≤ n)</li>
 <li>3. Recurrance: Blackjack(i) = max(outcome {-1,0,1}; + Blackjack(j) for # of hits in range(0, n) if valid play) where j is i + 4 + # of hits + # of dealer hits</li>
 <li>4. Topological Order: Create a DAG from the outcomes</li>
 <li>5. Solve Problem: Solve for max money earned</li>
</ul>

<h2>Lecture 21: Dynamic Programming III: Parenthesization, Edit Distance, Knapsack</h2>
<h3>Review</h3>
<ul>
 <li>1. Define subproblems</li>
 <li>2. Guess</li>
 <li>3. Recurrance</li>
 <li>4. Recursive Algorithm / Bottom Up</li>
 <li>5. Solve Original Problem</li>
</ul>
<h3>Subproblems for Strings</h3>
The following subproblems will get through most dynamic programming problems:
<ul>
 <li>Suffixes x[i:] for all i. O(n)</li>
 <ul>
  <li>For suffixes, topological order is almost always right to left</li>
 </ul>
 <li>Prefixes x[:i] for all i. O(n)</li>
 <ul>
  <li>For prefixes, topological order is almost always left to right</li>
 </ul>
 <li>Consecutive Substrings x[i:j] for all i ≤ j. O(n^2)</li>
 <ul>
  <li>For substrings, topological order is almost always by increasing substring size</li>
 </ul>
 As a rule of thumb, prefixes and suffixes are not going to be used together in the same problem, without substrings being in the problem as well
</ul>

<h3>Parenthesization</h3>
<ul>
 <li>Optimal evaluation of associative expression</li>
 <li>You have N matricies and want to compute their product</li>
 <li>If you have a vertical column * horizontal row * vertical column, there are 2 ways you can add parentheses:</li>
 <ul>
  <li>1. (vertical column * horizontal row) * vertical column <= Results in a large matrix & is O(n^2)</li>
  <li>2. vertical column * (horizontal row * vertical column) <= Results in a single vertical column & is O(n)</li>
 </ul>
 <li>Therefore, choice 2 is the optimal evaluation of the associative expression</li>
 <li>What is the outermost / last multiplication to occur? (A0...Ak-1) * (Ak...An-1)</li>
 <li>Take substrings of both (A0...Ak01) and (Ak...An-1).</li>
 <li>Takes O(n^3) to complete this problem</li>
</ul>
<h3>Edit Distance (& LCS)</h3>
<h4>Edit Distancec</h4>
Used for spell correction and DNA mutations
<ul>
 <li>Given two strings (x & y), what's the cheapest possible sequence of character edits to convert x -> y?</li>
 <ul>
  <li>Insert, delete, and replace are the allowed operations</li>
  <li>1. Subproblem: edit distance on x[i:] & y[j:] for all i & j, yields O(|x| * |y|) for # of subproblems</li>
  <li>2. Guess: You need the first character to match. To achieve this, there are 3 possible choices:</li>
  <ul>
   <li>1. replace x[i] with y[j]</li>
   <li>2. insert y[j] in front of x[i]</li>
   <li>3. delete x[i]</li>
  </ul>
  <li>3. Recurrance: </li>
  <ul>
   <li>DP(i,j) = min( (cost of replace x[i] with y[j]) + DP(i+1,j+1) ),</li>
   <li>DP(i,j) = min( (cost of insert y[j]) + DP(i, j+1) ),</li>
   <li>DP(i,j) = min( (cost of delete x[i] + DP(i+1,j) )</li>
  </ul>
  <li>4. Recursive Algorithm (Topological Order): Since this is a suffix problem, therefore, go from smaller to larger suffixes.</li>
  <li>5. Solve the Original Problem: Solve for DP(0,0); takes O(|x| * |y|)</li>
 </ul>
</ul>
<h4>Longest Common Subsequence</h4>
<ul>
 <li>Given two strings (x & y), what's the cheapest possible deletions of character edits to convert x -> y?</li>
 <li><b>H</b>I<b>E</b>ROG<b>L</b>YPHO<b>LO</b>GY -> MIC<b>H</b>A<b>EL</b>ANGE<b>LO</b>. What is the longest common subsequence? HELLO
</ul>
<h3>Knapsack</h3>
<ul>
 <li>List of items with a given size (si <- Integer) and value (Vi) that fit within the size of the sack (S)</li>
 <li>You want to choose a subset of the items to fit within the bag that gives the highest possible value</li>
 <li>1. Subproblem: suffix [i:] of items & remaining capacity X is greater than 0 in relation to S</li>
 <ul>
  <li># of subproblems: O(n*S)</li>
 </ul>
 <li>2. Guessing: Is item i included or not? <- 2 choices: yes or no</li>
 <li>3. Recurrance: DP(i,X) = max(DP(i+1,X), DP(i+1, X-si)+Vi)</li>
 <li>4. Recursive topological sort: O(n*S) PSEUDOPOLYNOMIAL</li>
</ul>
<h3>Pseudopolynomial Time</h3>
<ul>
 <li>Pseudo meaning it is one of the numbers in the input * the size of the input. In between polynomial and exponential</li>
</ul>

<h2>Lecture 22: Dynamic Programming IV: Guitar Fingering, Tetris, Super Mario Bros.</h2>

<h2>Lecture 23: Computational Complexity</h2>
<h3>Types of Computational Complexity</h3>
<ul>
 <li>P is the set of all problems you can solve in polynomial time</li>
 <li>EXP is the set of all problems you can solve in exponential time</li>
 <li>R is the set of all problems solvable in finite time</li>
</ul>
<h3>Examples of Problems</h3>
<ul>
 <li>Negative weight cycle detection: P Time</li>
 <li>NxN Chess: EXP Time -> Not P</li>
 <li>Tetris: EXP Time -> Unknown P</li>
 <li>Halting Problem: Given a computer program, does it ever stop running? -> Not in R</li>
</ul>
<h3>Decision Problems</h3>
<ul>
 <li>Decision problems are problems that result in a yes or no</li>
 <li>Most decision problems are uncomputable in finite time -> Not in R</li>
 <ul>
  <li>Programs are essentially interpreters for binary strings. Therefore, a program is a binary string, or a natural integer, between 0 and infinity</li>
  <li>Decision problems are a function that match inputs to yes or no</li>
  <li>Decision problems are contained within a set of all real numbers, not a set of all natural integers</li>
  <li>The set of real numbers is much larger than the set of integer numbers</li>
  <li>Therefore, almost every decision problem is impossible to solve, by any program</li>
 </ul>
</ul>
<h3>Nondeterministic Polynomials (NP)</h3>
<ul>
 <li>NP problems are a set of decision problems solvable in polynomial time, by a "lucky" algorithm</li>
 <li>The nondeterministic model is not a model of real computation, but rather a theoretical model. It makes guesses and gives an output of yes or no. In this model, guesses are guarenteed to lead to a yes answer if possible</li>
 <li>Tetris: Is there any way that the user can survive, given a specific set of blocks. If a yes is possible, NP will solve in polynomial time</li>
 <li>Another definition of NP: NP are a set of decision problems with solutions that can be "checked" in polynomial time</li>
 <li>Whenever the answer is yes, it is provable and checkable in polynomial time</li>
 <li>Proof in tetris would be surviving the level</li>
 <li>Most people believe P ≠ NP, but it has not been proven yet</li>
</ul> 
<h3>Hardness & Completeness</h3>
<ul>
 <li>NP-Hard means that a problem is as hard as every other problem in NP (this means it could also be harder than NP)</li>
 <li>Tetris is an NP-Hard problem</li>
 <li>Tetris is also NP-Complete</li>
 <li>NP-Complete is both within P and NP, but definitely not R</li>
 <li>In other words, when -Hard is added, it means greater than, when nothing is added it means less than, when -Complete is added, it means equal to</li>
</ul>
<h3>Reductions</h3>
<ul>
 <li>Convert a problem you don't know how to solve into a problem you do know how to solve</li>
 <li>Example: Using dijkstra's algorithm, a weighted graph algorithm, to solve for an unweighted graph. Not efficient, but doable</li>
 <li>Example: Longest path to shortest path: negate all the weights</li>
</ul>

<h2>Lecture 24: Topics in Algorithms Research</h2>
<ul>
 <li>Geometric Folding Algorithms: Foldability and Design</li>
 <ul>
  <li>Foldability: Algorithms to fold a piece of paper into its completed form. Unfortunately, this is NP-Complete</li>
  <li>Design: Create a shape and work backwards to making the folds in paper. Can be solved in polynomial time</li>
  <li>There's an algorithm, given any set of polygons in the plane, you can fold and make one straight cut to get exactly those polygons</li>
 </ul>
 <li>Memory transfers from DRAM to SRAM take a long time. Therefore, large amounts of data are transferred in blocks, to make the slower time more acceptable</li>
</ul>
 



<h1>Design and Analysis of Algorithms</h1>
<h2>Lecture 1: Course Overview, Interval Scheduling</h2>
<h2>Lecture 2: Divide and Conquer: Convex Hull, Median Finding</h2>
<h2>Lecture 3: Divide and Conquer: FFT</h2>
<h2>Lecture 4: Divide and Conquer: van Emde Boas Trees</h2>
<h2>Lecture 5: Amortization: Amortized Analysis</h2>
<h2>Lecture 6: Randomization: Matrix Multiply, Quicksort</h2>
<h2>Lecture 7: Randomization: Skip Lists</h2>
<h2>Lecture 8: Randomization: Universal and Perfect Hashing</h2>
<h2>Lecture 9: Augmentation: Range Trees</h2>
<h2>Lecture 10: Dynamic Programming: Advanced DP</h2>
<h2>Lecture 11: Dynamic Programming: All-Pairs Shortest Path</h2>
<h2>Lecture 12: Greedy Algorithms: Minimum Spanning Tree</h2>
<h2>Lecture 13: Incremental Improvement: Max Flow, Min Cut</h2>
<h2>Lecture 14: Incremental Improvement: Matching</h2>
<h2>Lecture 15: Linear Programming: LP, reductions, Simplex</h2>
<h2>Lecture 16: Complexity: P, NP, NP-Completeness, Reductions</h2>
<h2>Lecture 17: Complexity: Approximation Algorithms</h2>
<h2>Lecture 18: Complexity: Fixed-Parameter Algorithms</h2>
<h2>Lecture 19: Synchronous Distributed Algorithms: Symmetry-Breaking, Shortest Paths Spanning Trees</h2>
<h2>Lecture 20: Asynchronous Distributed Algorithms: Shortest Paths Spanning Trees</h2>
<h2>Lecture 21: Cryptography: Hash Functions</h2>
<h2>Lecture 22: Cryptography: Encryption</h2>
<h2>Lecture 23: Cache-Oblivious Algorithms: Medians and Matrices</h2>
<h2>Lecture 24: Cache-Oblivious Algorithms: Searching and Sorting</h2>

<h1>Advanced Data Structures</h1>
<h2>Lecture 1: Persistent Data Structures</h2>
<h2>Lecture 2: Retroactive Data Structures</h2>
<h2>Lecture 3: Geometric Data Structures I</h2>
<h2>Lecture 4: Geometric Data Structures II</h2>
<h2>Lecture 5: Dynamic Optimality I</h2>
<h2>Lecture 6: Dynamic Optimality II</h2>
<h2>Lecture 7: Memory Hierarchy Models</h2>
<h2>Lecture 8: Cache-Oblivious Structures I</h2>
<h2>Lecture 9: Cache-Oblivious Structures II</h2>
<h2>Lecture 10: Dictionaries</h2>
<h2>Lecture 11: Integer Models</h2>
<h2>Lecture 12: Fusion Trees</h2>
<h2>Lecture 13: Integer Lower Bounds</h2>
<h2>Lecture 14: Sorting in Linear Time</h2>
<h2>Lecture 15: Static Trees</h2>
<h2>Lecture 16: Strings</h2>
<h2>Lecture 17: Succinct Structures I</h2>
<h2>Lecture 18: Succinct Structures II</h2>
<h2>Lecture 19: Dynamic Graphs I</h2>
<h2>Lecture 20: Dynamic Graphs II</h2>
<h2>Lecture 21: Dynamic Connectivity Lower Bound</h2>
<h2>Lecture 22: History of Memory Models</h2>

<h1>Artificial Intelligence</h1>
<h2>Lecture 1: Introduction and Scope</h2>
<h2>Lecture 2: Reasoning: Goal Trees and Problem Solving</h2>
<h2>Lecture 3: Reasoning: Goal Trees and Rule-Based Expert Systems</h2>
<h2>Lecture 4: Search: Depth-First, Hill Climbing, Beam</h2>
<h2>Lecture 5: Search: Optimal, Branch and Bound, A*</h2>
<h2>Lecture 6: Search: Games, Minimax, and Alpha-Beta</h2>
<h2>Lecture 7: Constraints: Interpreting Line Drawings</h2>
<h2>Lecture 8: Constraints: Search, Domain Reduction</h2>
<h2>Lecture 9: Constraints: Visual Object Recognition</h2>
<h2>Lecture 10: Introduction to Learning, Nearest Neighbors</h2>
<h2>Lecture 11: Learning: Identification Trees, Disorder</h2>
<h2>Lecture 12: Neural Nets</h2>
<h2>Lecture 13: Deep Neural Nets</h2>
<h2>Lecture 14: Learning: Genetic Algorithms</h2>
<h2>Lecture 15: Learning: Sparse Spaces, Phonology</h2>
<h2>Lecture 16: Learning: Near Misses, Felicity Conditions</h2>
<h2>Lecture 17: Learning: Support Vector Machines</h2>
<h2>Lecture 18: Learning: Boosting</h2>
<h2>Lecture 19: Representations: Classes, Trajectories, Transitions</h2>
<h2>Lecture 20: Architectures: GPS, SOAR, Subsumption, Society of Mind</h2>
<h2>Lecture 21: Probilistic Inference I</h2>
<h2>Lecture 22: Probilistic Inference II</h2>
<h2>Lecture 23: Model Merging, Cross-Modal Coupling, Course Summary</h2>
